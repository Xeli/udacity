\documentclass[11pt]{article}
%Gummi|065|=)
\usepackage{amsmath}
\usepackage[hidelinks]{hyperref}
\title{\textbf{Machine learning Nanodegree\\ Capstone proposal}}
\author{Richard Deurwaarder}
\date{November 12th 2016}

\begin{document}

\maketitle

\section{Background}
This project is a Kaggle playground competition, called Dogs vs. Cats Redux: Kernels Edition\footnote{\url{https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition}}. Originally this competition was run in 2013. With deep learning being more popular these days they have reintroduced the competition. It makes for a nice view into the  progression of Machine learning over the last three years.
\section{The Problem}
The competition is about determining whether images are either cat or a dog by giving a probability to each image, 0 being cat, 1 being dog. The dataset is called the Asirra\footnote{Asirra: Animal Species Image Recognition for Restricting Access} data set. It consists of a training set with 25,000 images, half cats and the other half of dogs. The test set has 12,500 images.
\section{Solution workflow}
\subsection{Preprocessing the data}
I will need to preprocess the images because they're not all the same size. Creating a frequency table of the sizes of the images in the training set will guide me to the final image size my model will take as its input. The smaller images will be padded with grey pixels and the bigger images will be cropped. I might also grey scale the images, depending on how it will effect performance. Intuitively the color should not make much of a difference when determining if it's a cat or a dog, so it's a good way to reduce the complexity of the model, but it's something I need to test.

\subsection{Model}
After having cleaned up the dataset I want to try atleast two different but similar approaches. The first one would be using Inception\footnote{\url{https://github.com/tensorflow/models/tree/master/inception}} a model in the tensorflow framework. This has pretrained weights for image recognition. It uses a convolutional neural network.
The other approach would be to tweak my own convolution neural network (using tensorflow again), and see how to performs versus the inception model. Using a validation set I will determine which one of the model I will end up using.

\subsection{Evaluation} 
I'll use the following as loss function: 
\[ LogLoss = -\dfrac{1}{n}\sum\limits^{n}_{i=1}[y_i log(\hat{y}_i) + (1-y_i)log(1-\hat{y}_i)]
\]

This is the same loss funcion that Kaggle uses to evaluate the submissions of participants. You can read the logloss function as following, it averages the error for each classification (the $-\frac{1}{n}\sum\limits^{n}_{i=1}$ part). Inside of the sum is the error for each classification. It has two parts, each part calculating the error for when the images was a dog/cat and how our guess corresponds with that. For instance, if the image was a cat and we very confidently guess it's a dog, $y_i = 0$, $\hat{y}_i = 0.999$. The part inside of the sum would become: 
\[
y_i log(\hat{y}_i) + (1-y_i)log(1-\hat{y}_i) = 0 * log(0.999) + 1 * log(0.001) \approx -6.9
\]

After getting negated by the $-\frac{1}{n}$ this gives a very high logloss.
In other words when being very confidently wrong, the logloss will punish you very hard for it.
\section{Compare my model}
The competition already has some other submissions (200 at the time of writing) this will allow me to see what algorithms other people have used. In particular I'd like to test it versus the winning submission of 2013, it had 98,914\% correct classifications. Because the competition from 2013 is very similar, it is slightly different. For instance instead of probabilities participants had either pick a dog or cat, 0 or 1. For this reason I would also like to pick one of the submissions the current competition, the highest score so far is a LogLoss of 0.04220.

\end{document}
